% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{rotating}
\usepackage[pdftex,
            pdfauthor={Giuliano Belinassi, Richard Biener, Jan Hubicka and Alfredo Goldman},
            pdftitle={Compiling Files in Parallel: A Study with GCC},
            pdfsubject={Compiling in Parallel},
            pdfkeywords={Compilers, Parallel Compilation, Link Time Optimization, LTO},
            pdfproducer={LaTeX},
            pdfcreator={pdfTeX 3.14159265-2.6-1.40.21 (TeX Live 2020/Debian)}]{hyperref}

\usetikzlibrary{decorations.pathreplacing,shapes,arrows,positioning}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
\renewcommand\UrlFont{\color{blue}\rmfamily}



\begin{document}
\bibliographystyle{plainurl}

%
\title{Compiling Files in Parallel: A Study with GCC\thanks{Supported by CAPES and Google Summer of Code.}}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Giuliano Belinassi\inst{1} \and Richard Biener\inst{2} \and Jan Hubi\v cka \inst{2,3} \and Alfredo Goldman\inst{1}}
%
\authorrunning{G. Belinassi et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Institute of Mathematics and Statistics, Rua do Matão 1010, São Paulo SP, BRA\\
\url{https://www.ime.usp.br} \and
SuSE Labs, Nürnberg 90409, GER\\
\url{https://www.suse.com/} \and
Charles University, Malostransk én ám. 25. 11800 Praha, CZE\\
\url{https://cuni.cz/uken-1.html}}

%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}

Processors are becoming increasingly parallel; but compiling software has so
far been a task parallelizable only by the number of files in it. To improve
compilation parallelism granularity, we propose a method feasible to implement
in commercial compilers for single file parallel compilation, with simple
modifications in the Link Time Optimization (LTO) engine; which we show by
implementing it in GCC. This method resulted in a 35\% speedup when
self-compiling GCC when compared to \texttt{make -j} only parallelism, and
up to $3.5\times$ speedup when compiling individual files. We also found no
meaningful slowdown when compiling other applications with Jobserver disabled.
Finally, we explain why the adoption of our proposed method is still compatible
with the Reproducible Builds project.

\keywords{Compilers \and Parallel Compilation \and Link Time Optimization \and LTO.}
\end{abstract}
%
%
%
\section{Introduction}

The recent advances in both technological and computational fields induced an
increasingly faster expansion of software ecosystems. Developers create new
programs to supply the needs of the most diverse domains, either through web
systems coded in script languages; or by components to an operating system
destined to control some hardware resources. Regardless of the reason behind
the development of them, it is true that their code will be, at some
point, transformed into machine language by a compiler or assembler, even if an
interpreter executes it.

Compilers are enormous programs, largely adopted by industry and academia, where
a great effort has been employed to produce efficient code --
but without any sacrifice in correctness --. There are huge projects destined
to develop and improve them, such as the GNU Compiler Collections
(GCC\footnote{https://gcc.gnu.org/}) and LLVM\footnote{https://llvm.org/}, capable
of translating several languages such as C, C++, and Fortran, to machine language.

GCC was started by Richard Stallman, with the first public release in March of
1987. Back then, it
only supported the C language, but already allowed code generation for several
architectures \cite{gcc-first-ver}. Today, GCC is a multinational collaboration
project, with more than 412230 lines of code, and perhaps the most used C/C++
compiler in Linux environments.

GCC was Initially designed to compile programs a single file at time, meaning
that it could not allow global cross-file optimizations because the compiler
never had the opportunity to analyze the program as a whole. This scenario
changed when Link Time Optimization (LTO) was proposed \cite{whoprgoogle} and
implemented in GCC \cite{glek2010optimizing}. GCC supports LTO by using
\texttt{-flto}. Part of the LTO engine has already been parallelized, which
inspired this work.

This work tries to answer the question about how can we modify a
industrial scale compiler to compile single files in parallel. We address
that by reusing the already-existing LTO engine in it (in this
case, GCC) for partitioning the single file Compilation Unit after the
Interprocedural Optimizations has been decided, and we proceed compiling
each partition individually, in parallel.

We present the previous efforts in compiling a single file in
parallel, as well as an introduction to LTO in Section \ref{sec:related}.
Then we detail our work in single file compilation in
Section \ref{sec:work}, while exposing some internal mechanisms
of GCC. We then show how we ensured that our modifications are correct
in Section \ref{sec:methods}. Finally, we present our results in
Section \ref{sec:results} and discuss how to improve from this paper
in Section \ref{sec:future_works}.

\section{Related Works} \label{sec:related}

Parallel Compilation includes parsing (parallel or not),
how to perform analysis, optimization, and code translation in parallel.
Given an alphabet $\mathrm{\Sigma}$, parsing can be described as building a machine to decide if
an input string $w \in \mathrm{\Sigma}^*$ is a member of a certain language $L
\subseteq \mathrm{\Sigma}^*$ or not, creating the Abstract Syntax Tree in the
process by logging the used derivation rules.

Parallel Parsing dates back to 1970. Lincoln \cite{Lincoln:1970:PPT:987475.987478}
explored how to use the vectorial registers in the (so far)
STAR-100 supercomputer for lexical analysis. Fischer
\cite{fischer1975parsing} gives a detailed theoretical study, proving
several concurrent parsing techniques for LR($k$), LALR($k$) and SLR($k$).
The parser proceeds by breaking the input in several arbitrary parts, and running a
serial parser on each of them. Then the algorithm tries to
recover the stack of each noninitial parser by constructing a set of
possible states, for which there are 5 possible cases. However, in case
of an error, the parser result should be discarded, and therefore a lot
of work will be done in vain when comparing with the sequential version.

Perhaps the most interesting work is by Barenghi \textit{et. al.}
\cite{Barenghi:2015:PPM:2839536.2840146}, where they explore properties of
Operator Precedence Grammars to construct an Yacc-like parser constructor named
PAPAGENO, which generates parallel parsers. The authors described
precedence grammars for Lua and JSON, which they used in their tests to get
a speedup of up to $5.5\times$ when compared to a parser generated by
GNU Bison.

As for parallel compilation \textit{de facto}, we found two relevant works by
Vandevoorde \cite{vandevoorde1988parallel} for C, and Wortman and Junkin
\cite{wortman1992} for Modula-2+.  The former assumes that every function
declaration is in the file headers, and implements per-function and
per-statement parallel compilation. The letter implements only per-function
parallelism.  Speedups ranged from $1.5\times$ to $6\times$ on a multicore
MicroVAX II machine. None of these papers discuss optimization, and they
concentrate on (today perspective) non-optimizer compilers, which are not
the case of GCC. 

There has been an attempt of parallelizing GCC by threading the GIMPLE
Intraprocedural pass manager \cite{bernardino2020improving}. An optimization is
called Intraprocedural if it only requires information contained inside its body.
The \textit{vectorizer} is an example of this. The authors managed a speedup of up to
$3.35\times$ to this compilation stage, and up to $1.88\times$ in
total compilation of a file when extending this technique to the RTL passes.

\subsection{Link Time Optimization (LTO)} \label{lto_section}

Compilation usually uses the following scheme: a compiler consumes a source file,
generating an assembler file as output. This file is then assembled into an object file,
and later linked with the remaining objects file to compose an executable or a library.
Fig. \ref{fig:gnu_toolchain} illustrates this process for a single file. In this paper,
we call this method the Classical Compilation scheme.

\begin{figure}
\tikzstyle{block} = [rectangle, draw, fill=white,
    text width=6em, text centered, rounded corners, node distance=4.7cm, auto, minimum height=2em]
\tikzstyle{line} = [draw, -latex]
\tikzstyle{cloud} = [draw, ellipse,fill=white, node distance=2cm,
    minimum height=2em]
\makebox[\textwidth][c]{
\scalebox{0.8}{
\begin{tikzpicture}[node distance = 3cm, auto]
    % Place nodes
    \node [block]                      (cc1) {Compiler \\ (cc1)};
    \node [block, right of = cc1]      (as) {Assembler\\(as)};
    \node [block, right of = as]       (ld) {Linker\\collect2 or ld};
    \coordinate [left of=cc1]          (fonte);
    \coordinate [right of=ld]    (bin);

    % Draw edges
    \draw[->]    (cc1.east)    -- (as.west)       node[midway, above] {Assembler File};
    \draw[->]    (cc1.east)    -- (as.west)       node[midway, below] {(.s)};
    \draw[->]    (as.east)     -- (ld.west)       node[midway, above] {Object File};
    \draw[->]    (as.east)     -- (ld.west)       node[midway, below] {(.o)};
    \draw[->]    (fonte.west)  -- (cc1.west)      node[pos=0, above] {Source File};
    \draw[->]    (fonte.west)  -- (cc1.west)      node[pos=0, below] {(.c)};
    \draw[->]    (ld.east)     -- (bin.west)      node[pos=1, above] {Executable};
\end{tikzpicture}
}
}%
\caption{GCC Compiling a .c file in Classical Compilation mode}
\label{fig:gnu_toolchain}
\end{figure}

The issue around the Classical Compilation scheme is that it can only optimize with
the information found in its Compilation Unit because it can not see the body
content of functions in other files of the project. A Compilation Unit is the
entire content of a source file (a .c file in C) plus all headers it includes.

As an answer to this, LTO allows cross-module optimizations by
postponing optimizations and final translation to a linker wrapper. There, the entire
program can be loaded by the compiler (but more often, just some sort of summary)
as a single, big Compilation Unit, and optimizations can be decided globally,
as now it has access to the internals of other modules. LTO is divided into
three steps \cite{whoprgoogle,glek2010optimizing}:
\begin{itemize}
\item LGEN (\textit{Local Generation}): each module is translated to an Intermediate
Representation (IR) and written to disk in phony object files. These objects do
not contain assembler code, and therefore can not be linked by a default linker
such as \textit{ld} (unless fat objects are enabled, in this case, the assembler is also
generated and dumped together with the IR). This step runs serially
on the input file (\textit{i.e.} in parallel with regard to the files in the project).

\item WPA (\textit{Whole Program Analysis}): load all translated modules, merges
all Compilation Units into one, and analyzes the program globally.
Then it generates a log of transformations for the program, and this global
Compilation Unit is partitioned for the next stage. This analysis runs sequentially
to the entire project.

\item LTRANS (\textit{Local Transformations}): apply the transformations generated by
WPA to each partition, which will generate its own object file. This stage runs in
parallel.
\end{itemize}

This process is sketched in Fig. \ref{fig:whopr_build}, where the linker
wrapper is represented by \textit{collect2}, which firstly launch \textit{lto1}
in WPA mode, and the second time it finally launches \textit{ld}. This process
can be seen by launching gcc with \texttt{-flto -v}.

\begin{figure}
\tikzstyle{block} = [rectangle, draw, fill=white,
    text width=6em, text centered, rounded corners, node distance=1cm and 0.5cm, minimum height=2em]
\tikzstyle{line} = [draw, -latex]
\makebox[\textwidth][c]{

\scalebox{0.8}{
\begin{tikzpicture}[node distance = 3cm, auto]
    % Place nodes
    \node [block]              (fonte1) {source1.c};
    \node [block, right= of fonte1]        (fonte2) {source2.cpp};
    \node [block, right= of fonte2]        (fonte3) {source3.f90};
    \node [block, above= of fonte2]         (make)   {Makefile};

    \node [block, below= of fonte1]        (gcc)      {gcc};
    \node [block, below= of fonte2]        (g++)      {g++};
    \node [block, below= of fonte3]        (gfortran) {gfortran};

    \node [block, below= of gcc]           (objeto1) {obj1.o};
    \node [block, below= of g++]           (objeto2) {obj2.o};
    \node [block, below= of gfortran]      (objeto3) {obj3.o};

    \node [block, below= of objeto2]       (gcc_lto) {collect2 (lto1)};

    \node [block, right= of fonte3]            (gcc_ltrans1) {gcc\_ltrans};
    \node [block, right= of gcc_ltrans1]   (gcc_ltrans2) {gcc\_ltrans};
    \node [block, right= of gcc_ltrans2]   (gcc_ltrans3) {gcc\_ltrans};

    \node [block, above= of gcc_ltrans2]       (gcc_wpa) {gcc\_wpa};
    \coordinate[below= of gcc_wpa]            (c2);


    \node [block, below= of gcc_ltrans1]   (obj1) {obj1.o};
    \node [block, below= of gcc_ltrans2]   (obj2) {obj2.o};
    \node [block, below= of gcc_ltrans3]   (obj3) {obj3.o};

    \node [block, below=of obj2]   (ld) {collect2 (LD)};

	\node [block, below=of ld]   (bin) {Binary};

    % Draw edges
    \draw[->]    ([xshift=-0.7em] make.south)   -- (fonte1.north);
    \draw[->]    (make.south)   -- (fonte2.north);
    \draw[->]    ([xshift=+0.7em] make.south)   -- (fonte3.north);

    \draw[->]    (fonte1.south)   -- (gcc.north);
    \draw[->]    (fonte2.south)   -- (g++.north);
    \draw[->]    (fonte3.south)   -- (gfortran.north);

    \draw[->]    (gcc.south)   -- (objeto1.north);
    \draw[->]    (g++.south)   -- (objeto2.north);
    \draw[->]    (gfortran.south)   -- (objeto3.north);

    \draw[->]    (objeto1.south)   -- ([xshift=-0.7em]gcc_lto.north);
    \draw[->]    (objeto2.south)   -- (gcc_lto.north);
    \draw[->]    (objeto3.south)   -- ([xshift=+0.7em]gcc_lto.north);

    %\draw[->]    (gcc_lto.south)   -- (gcc_wpa.north);
 	\draw[->]  (gcc_lto.east) .. controls +(6.5,0) and +(-6.5,0).. (gcc_wpa.west);

    \draw[->]    (gcc_wpa.south)   -- (gcc_ltrans1.north);
    \draw[->]    (gcc_wpa.south)   -- (gcc_ltrans2.north);
    \draw[->]    (gcc_wpa.south)   -- (gcc_ltrans3.north);

    \draw[->]    (gcc_ltrans1.south)   -- (obj1.north);
    \draw[->]    (gcc_ltrans2.south)   -- (obj2.north);
    \draw[->]    (gcc_ltrans3.south)   -- (obj3.north);

    \draw[->]    (obj1.south)   -- ([xshift=-0.7em]ld.north);
    \draw[->]    (obj2.south)   -- (ld.north);
    \draw[->]    (obj3.south)   -- ([xshift=+0.7em]ld.north);

	\draw[->]    (ld.south)   -- (bin.north);
	
	%draw brackets
\draw [decorate,decoration={brace,amplitude=10pt},xshift=-0.5cm,yshift=0pt]
([xshift=-1.3cm]objeto1.south) -- ([xshift=-1.3cm]fonte1.north) node [black,midway,xshift=-0.3cm]
{\footnotesize \begin{turn}{90}LGEN\end{turn}};

\draw [decorate,decoration={brace,amplitude=10pt},xshift=-0.5cm,yshift=0pt]
([xshift=1.3cm]gcc_ltrans3.north) -- ([xshift=1.3cm]obj3.south) node [black,midway,xshift=0.3cm]
{\footnotesize \begin{turn}{-90}LTRANS\end{turn}};


\end{tikzpicture}
}
}%
\caption{Compilation of a program using LTO scheme}
\label{fig:whopr_build}
\end{figure}

\section{Our Proposal} \label{sec:work}

As presented in Section \ref{lto_section}, LTO was created to allow
cross-module optimizations in programs, and has a serial part (WPA), imposing a
bottleneck on manycore machines. On the other hand, Classical Compilation
scheme can not partition its Compilation Unit for parallel
compilation, which can also bottleneck the compilation if it is too large.
The latter issue, however, can be solved by transplanting the LTO partitioner
to the Classical Compilation scheme, and making it work \textit{without}
having the context of the \textit{entire} program. We claim that it is possible,
and show that by implementing it in GCC.

Our approach differs from LTO mainly in how we handle the Interprocedural
Optimization. An optimization is called Interprocedural if it requires
information of the body of other functions to optimize a certain function.
An example of such optimizations is the \textit{inliner}.
LTO handles these optimizations with the context of the whole program, while
our approach will only have the context of the original Compilation Unit.
This allows optimizations as good as they are in the Classical
Compilation scheme while benefiting of the extra parallelism opportunity
available in the LTO's LTRANS stage.

In this section, we will first discuss the internals of some parts of GCC,
which we had to modify for our implementation to work. In Subsection
\ref{sec:gcc_driver}, we present an important piece of the compiler from the
User Experience perspective: the \texttt{gcc} \textit{driver}. Then, in
Subsection \ref{sec:lto_partitioner} we present a short algorithm for making
the LTO partitioner work for our proposal. In Subsection
\ref{sec:partition_mask} we present a necessary change we had to do in our work
about how partitions are applied in GCC. In
Subsection \ref{sec:name_clash_resolution}, we explain how we solved the issue
of private symbols with the same name being promoted to global.
Then in Subsection \ref{sec:integration_jobserver} we present an opitional part
of our work about communicating with the GNU Make Jobserver to keep track of
used processors. And finally, we discuss why our proposal is still compatible
with the Reproducible Builds project in Subsection \ref{sec:repro_builds}.

\subsection{The GCC driver}\label{sec:gcc_driver}

A large program can be written in several languages, with each of them having
its own compiler. From a Compiler Theory perspective, a compiler
translates a program from a language $A$ to an language $B$
\cite{dragonbook}. In GCC, it translates several languages, such
as C, to Assembler of some architecture (\textit{e.g.} x86). This means that
encapsulating code in object files, or linking the code in an executable, are
not tasks of the compiler. However, the user can launch \texttt{gcc -o binary
file.c} and get a working binary. That is because the binary \texttt{gcc} is
a \textit{driver}, and it will launch the
necessary programs for the user. In fact this line launches three programs,
as illustrated in Fig. \ref{fig:gnu_toolchain}.

Therefore, if we want our changes do not break the building scripts
(\textit{e.g.}, Makefile) used by most
projects -- which is mostly launching \texttt{gcc file.c -c} and creating an object file \texttt{file.o} -- we must ensure that we create a single object file for each file,
not multiple, as does the LTO partitioner. Fortunately we can rely on GNU \textit{ld}
partial linking for merging objects file into one. Therefore, the solution to this problem
is:
\begin{enumerate}
	\item Patch the \textit{partitioner} to communicate the location of
	each file created to the \textit{driver}. If the \textit{partitioner}
	is the compiler (which is the case of GCC), then it should communicate
	the location of each generated \textit{assembler file}. This can be
	archived by passing a hidden flag \texttt{-fadditional-asm=<file>}
	by the driver to the partitioner, which the last will write to. This file can also
	be replaced with a Named Pipe for better performance if needed.

	Then, the partitioner checks if this flag has been passed to the compiler. If yes, then
	a \textit{compatible version} of the driver is installed. If the
	partitioner decides to partition the Compilation Unit, it should
	\textit{retarget} the destination assembler file and write the retargeted
	name to the communication file.

	\item Patch the driver to pass this hidden flag to the
	\textit{partitioner}, and also check if this file exists. If not, it means that
	either the compiler is incompatible (assuming it did not halt with an
	error) or it has chosen not to partition the Compilation Unit. In the first
	case, the driver should call \textit{as} to every assembler file generated, and call
	the linker to generate the expected final object file. In the second case,
	simply fallback to the previous compilation logic.
\end{enumerate}

Fig. \ref{fig:gnu_toolchain_patched} illustrates the code flow after these
changes.  The execution starts in the highlighted node \textit{Driver}, which
calls the compiler with the necessary flag to establish a communication between
the parts. The compiler then will partition the Compilation Unit and forks
itself into several child processes, one for each partition. Although there is
a clear difference between a \textit{process} and a \textit{thread}, we will
use this term interchangeable in this work.

Once multiple processes are created, the the compiler will communicate its
output .s file to the driver, and the driver then will launch the \textit{as}
to assemble it, and then launch \textit{ld} to merge them all into a single
object file.

After these changes, a good way to check if the changes are working is to
bootstrap the compiler with a single partition, but writing the output
path into the created communication channel. Bootstrapping can be a resource
intensive task; therefore this is an excellent opportunity to write automated
tests covering every case necessary for the bootstrap. This may also expose
some extreme cases, for instance, the C compiler being called to process macros
in files of distinct languages.

\begin{figure}
\tikzstyle{block} = [rectangle, draw, fill=white,
    text width=6em, text centered, rounded corners, minimum height=2em]
\tikzstyle{line} = [draw, -latex]

\makebox[\textwidth][c]{
\scalebox{0.8}{
\begin{tikzpicture}[node distance = 2.4cm, auto]
    % Place nodes
    \node [block]                      (cc1_1) {cc1};
    \coordinate [right= of cc1]          (c);
    \node [block, right= of c,fill={rgb:black,1;white,2}]        (driver1) {Driver};
    \node [block, above= of c]                      (cc1_2) {cc1};
    \node [block, below= of c]                      (cc1_3) {cc1};
    \coordinate [above= of driver1]          (c2);
    \coordinate [below= of driver1]          (c3);
    \node [block, right= of c2]      (as2) {as};
    \node [block, right= of c3]      (as3) {as};
    \node [block, right= of driver1]       (ld) {ld};
    \coordinate [left= of cc1]          (fonte);
    \coordinate [right= of ld]    (bin);

    % Draw edges
    \draw[->]    (driver1.west)    -- (cc1_1.east) node[midway, above] {\texttt{-fadditional-asm=<file>}};
    \draw[->]    ([xshift=+0.5cm]cc1_2.south) -- ([xshift=-0.5cm]driver1.north) node[midway, above, sloped] {Generates .s file};
    \draw[->]    ([xshift=+0.5cm]cc1_3.north) -- ([xshift=-0.5cm]driver1.south) node[midway, above, sloped] {Generates .s file};

    \draw[->]    (cc1_1.north)    -- ([xshift=-0.5cm]cc1_2.south) node[midway, above, sloped] {Forks};
    \draw[->]    (cc1_1.south)    -- ([xshift=-0.5cm]cc1_3.north) node[midway, above, sloped] {Forks};

    \draw[->]    ([xshift=+0.5cm]driver1.north)  -- (as2.south) node[midway, above, sloped] {Assemble received .s};
    \draw[->]    ([xshift=+0.5cm]driver1.south)  -- (as3.north) node[midway, above, sloped] {Assemble receibed .s};
    \draw[->]    (driver1.east)  -- (ld.west) node[midway, above, sloped] {Links};

%    \draw[->]    (cc1.east)    -- (as.west)       node[midway, above] {Assembler File};
%    \draw[->]    (cc1.east)    -- (as.west)       node[midway, above] {Assembler File};
%
%    \draw[->]    (cc1.east)    -- (as.west)       node[midway, below] {(.s)};
%    \draw[->]    (as.east)     -- (ld.west)       node[midway, above] {Object File};
%    \draw[->]    (as.east)     -- (ld.west)       node[midway, below] {(.o)};
%    \draw[->]    (fonte.west)  -- (cc1.west)      node[pos=0, above] {Source File};
%    \draw[->]    (fonte.west)  -- (cc1.west)      node[pos=0, below] {(.c)};
    \draw[->]    (ld.east)     -- (bin.west)      node[pos=1, above] {\texttt{file.o}};
\end{tikzpicture}
}
}%
\caption{Interaction between the \textit{driver}, the \textit{compiler}, and other tools
after our changes}
\label{fig:gnu_toolchain_patched}
\end{figure}

\subsection{Adapting the LTO Partitioner}\label{sec:lto_partitioner}

In GCC, a Compilation Unit is represented as a callgraph. Every function,
global variable, or clones (which may represent a function to be inlined)
is represented as nodes in a callgraph. If there is a function call from $f$
to $g$, then there is an edge from $f$ to $g$. Similarly, if there is a
reference to an global variable $v$ in $f$, then there is also an edge from $f$
to $v$. This means that Compilation Unit partitioning can be represented as
a Graph Partitioning problem. 

When LTO is enabled and GCC is in the WPA stage, the body of these nodes
is not present, just a \textit{summary} of it (\textit{e.g.} the size
in lines of code it had). This is done to conserve memory. However,
when LTO is disabled, the function body is present, resulting
in some assertion failures, which were fixed after some debugging.

Then comes the partitioner algorithm \textit{de facto}. In LTO, GCC tries to
create partitions of similar size, and always try to keep nodes together. The
heuristic used by the original partitioner runs in linear time, and because of
that its code is quite complex. This resulted in a difficult process of finding
and solving the issues causing a partitioning failure, and therefore, we
decided to design a new partitioning algorithm for this project.

This partitioning algorithm works as follows: for each node, we check if they
are a member of a COMDAT group, and
merged it into the same partition. We then propagate outside of this COMDAT group;
checking for every node that may trigger the COMDAT to be copied into other
partitions, and also add them to the same partition. In practice,
this means to include every node hit by a Depth-First
Search (DFS) from the group to a non-cloned node outside of the group.
Fig. \ref{fig:comdat_frontier} represents a sketch of this process.

\begin{figure}
\centering
	 \includegraphics[scale=0.8]{figuras/comdat_frontier.pdf}
	  \caption{Example of callgraph, in beige being represented the COMDAT group,
	  in green the COMDAT frontier, and in red the cloned nodes.}
	  \label{fig:comdat_frontier}
\end{figure}

At first we also did this process for private functions to avoid
promoting them to public, once external access would be necessary if they go
into distinct partitions. However, results showed that this has a strong
negative hit in any parallelism opportunity. For grouping the nodes together,
we used an Union Find with Path Compression, which yields an attractive
computational complexity of $O(E + N \lg^*N)$ to our partitioner, where $N$ is the
number of nodes and $E$ is the number of edges in the callgraph \cite{feufiloff}.

Once the partitions are computed, we need to compute its \textit{boundary}.
If function $f$ calls $g$, but they were assigned into distinct partitions,
then we must include a version of $g$ in $f$'s partitions without its body,
then check if $g$ is a private function. If yes, then $g$ must be promoted
to a public function. There is also extra complexity if a version of $g$
is marked to be inlined in $f$, which means that its body has to be
streamed somehow. Fortunately, most of this logic is already present
in LTO and we could reuse them. However, some issues were found
when handling inline functions and global variables marked as part
of the boundary. First, some functions marked to be inlined into 
functions inside the partition were incorrectly marked to be removed.
Second being variables marked as in the boundary (and therefore
not in the partition) not being correctly promoted to external. The reason
for these issues were hard to find the reason of, but easy to fix.

Furthermore, there were some issues concerning how GCC handle
partitions, which we discuss in the next subsection.

\subsection{Applying a Partition Mask}\label{sec:partition_mask}

Once partitions are computed, the only presented way to apply it (\textit{i.e.},
remove every unnecessary node from the Compilation Unit) was to reload the
compiler, and let it load the phony object files, which are not available in our
project because we are not running in LTO mode. We developed another method for this.
We used the Unix \textit{fork} function to spawn a child process, and then
we implemented our own method to apply the partition without having to load
these phony object files. Fortunately, this consisted
of four cases:
\begin{itemize}
	\item \textit{Node is in partition}: nothing has to be done.
	\item \textit{Node is in boundary, but keep its body}: we mark that this function
	is available in other partition, but we do not release its body or
	datastructures.
	\item \textit{Node is in boundary}: we mark this mode as having its body removed,
	but we never actually remove it. This is because the node may share the
	body contents with another node in the partition. We then remove
	every edge from its functions to it callees, all references to variables,
	the content of the Dominator Tree, and also its Control-Flow Graph. This
	is now a function which this partition only know that it exists.
	\item \textit{Node not in boundary}: we remove the node, and all its content.
\end{itemize}

After this, it retargets the output assembler file to another file private to
this partition and write its partition number together with the path to the
communication file, which the driver will read in the future. The partition
number is important to guarantee that the build is reproducible, as we will
discuss later.

It is also important that some early step in the compiler does not emit assembler
too early, such as the issue with the Gimplifier in GCC, or else the output
file will be incomplete. We had to fix the gimplifier to avoid that.

Once the partition is applied to the current process, and the output file has
been communicated to the driver, it can continue with the compilation. It
should be running in parallel now by the number of partitions.

\subsection{Name Clash Resolution}\label{sec:name_clash_resolution}

In LTO, if there are two promoted symbols to global with the same name, it is
quite straightforward to fix this issue. Since we have the context of the
entire program, we can simply increment a counter for each clashed symbol and
rename them. However, we have not the context of the entire program, and we
have to find another way of fixing it.

One will be tempted to simply select an random integer and append to the name.
This is not a good idea, once it will break bootstrap because each
compilation will result in a different object file. Using the address of the
function in memory does not work either, as the first bootstrap step has the
compiler compiled with \texttt{-O0} and the second step with \texttt{-O2}, and
memory address will certainly be different.

The solution is to
use a crc32 hash of the original file and append it to the function's name,
since we can not have two functions with the same (mangled) name in the program.
There is still a tiny probability of name clash with this approach, however we did
not find any on our tests.

\subsection{Integration with GNU Make Jobserver}\label{sec:integration_jobserver}

GNU Make is able to launch jobs in parallel by using \texttt{make -j}. This
is so simple and yet so powerful that even recent building scripts (such as CMake)
relies on Make for launching jobs.

In order to avoid unnecessary partitioning and job creation, we have also
implemented a integration mechanism with GNU Jobserver \cite{posixjobserver}.
The implementation
is simple: we query the server for an extra token. If we receive the token,
then it means that some processor is available, and we can partition the
Compilation Unit and launch jobs inside the compiler. Else, the processor
workload is full, and it may be better to avoid partitioning altogether.

However, for a program to be able to communicate with the jobserver,
it should be launched with a prepended \texttt{+} character,
for example $\texttt{+gcc -c file.c}$, and therefore it is not
so straightforward to use this mode on existing projects.

\subsection{Relationship with Reproducible Builds}\label{sec:repro_builds}

One interesting point of Open Source is that it can be verified by everyone.
However, very often these projects are distributed in a binary form to the
users, removing them the burden of this process. But there is nothing
avoiding that a malicious developer modifies the codebase \textit{before}
the distribution (\textit{e.g.} inserting a backdoor), and claiming that
he got a distinct binary because his/her system is different from the user.

The Reproducible Builds aims to solve that issue by providing a way to
reproduce the released binary from its source. Some software needs to
be patched in order to work with Reproducible Builds, for instance,
to not contain some kind of build timestamp, and so on. A build
is called \textit{reproducible} if given the same sourcecode and build
instructions, anyone can recreate a bit-perfect version of the distributed
binary \cite{reproducible_builds}.

To keep compatibility with this project, we must ensure that our compiler
always output the same code with a given input. The input is not only
the source file itself, but also the flags passed to it.

We claim that our modification still supports the Reproducible Builds because
of the following reasons:

\begin{enumerate}
	\item No random information is necessary to solve name clashing.
	\item Given a number of jobs, our partitioner will always generate
	the same number of partitions for a certain program, always with the same content.
	\item Partial Linking is always done in the same order. To ensure that,
	we communicate to the driver a pair (\textit{partition number, path to file}),
	and we sort this list using the partition number as key.
	\item No other race conditions are introduced, as we rely on the quality of
	the LTO implementation of the compiler.
\end{enumerate}

However, there is one point of concern, which is the Jobserver Integration.  If
the processor is already in 100\% usage, we avoid partitioning at all and
proceed with sequential compilation. This certainly changes from computer to
computer, and therefore the build is not guaranteed to be reproducible if this
option is enabled. This is not an issue if the number of jobs is determined
beforehand.

\section{Methods and Current Issues}\label{sec:methods}

We ensure the correctness of our changes by:
\begin{enumerate}
	\item Bootstrap GCC with the number of parallel jobs as 2, 4, 8 and 64, with
	minimum partitioning quota of $10^3$ and $10^5$ instructions. We found issues
	with regard to how the \textit{ipa-split} pass generated clones, and therefore
	we have disabled it for now. This pass breaks big functions
	into a header and a body, and marks the header to be inlined to the caller.
	A bug in our implementation marked such clones as being an external function in
	rare cases, which the linker can not find.

	\item Run the GCC testsuite, which we noticed that all tests related to the debug
	symbols were failing. However, if \texttt{-g0} is passed, no debug symbol is created,
	and the bug related to this issue is never triggered. The reason behind this is
	because our partition applier do not remove the symbols associated with removed
	nodes, resulting in unknown symbol being dumped into assembler.

	\item Generated random programs with \textit{csmith} \cite{yang2011finding}. This found more complicated
	bugs (for instance, long strings being output before the assembler file retarget),
	which we fixed.
\end{enumerate}

Then for the time measurements, we sampled $n = 15$ points for each file from
the GCC project, which we present the average in the graphics. The errorbars
represents 95\% confidence interval for the sample average. Furthermore, each
file were preprocessed by the C preprocessor, so it could be compiled independently
of other files.

For the projects, each point represents a mean were compiled with $n = 5$ points,
because this is a more computer intensive task. The errorbars also represent a 95\%
confidence interval of the average. We also were sure that the serial data was also
compiled with \texttt{-g0} for fairness.

Tests were mainly executed in two computers, which are represented
in the Table \ref{table:machines}. The graphic caption specify where the test
was run.

The version of GCC used in the tests is available in the \texttt{autopar\_europar\_2021}
branch of \texttt{git://gcc.gnu.org/git/gcc.git}, with hash \texttt{e2da2f7205}.


\begin{table}[]
\begin{tabular}{c|c|c|c|c|}
\cline{2-5}
                                      & Number of Cores & Number of Threads & RAM                                                    & Disk Type \\ \hline
\multicolumn{1}{|c|}{Core-i7 8650U}   & 4               & 8                 & \begin{tabular}[c]{@{}c@{}}8Gb \\ DDR4\end{tabular} & SSD       \\ \hline
\multicolumn{1}{|c|}{4x Opteron 6376} & 32              & 64                & \begin{tabular}[c]{@{}c@{}}252Gb\\ DDR3\end{tabular}   & HDD       \\ \hline
\end{tabular}
\caption{Machine specification of tests}
\label{table:machines}
\end{table}

\section{Results}\label{sec:results}

We first highlight our best results. We managed a $2.4\times$ and
$2.25\times$ speedup on the Core-i7 machine when compiling the files
\textit{gimple-match.c} and \textit{insn-emit.c}, which are autogenerated
files from the GCC project, and takes quite long to compile
($76s$ and $23s$ sequential). For non-generated files, we have
\textit{tree-vect-stmt.c}, with a $2.14\times$ speedup and taking
$11s$ sequentially. All these
speedups were archived by using 8 parallel jobs. Fig. \ref{fig:gcc_all_files} shows the results globally. Here we can see that for files with $\textit{Number of Instructions} >
1 \times 10^5$, we have mostly significant improvements.

Now we move to the $4\times$ Opteron machine. We managed a
$3.32\times$, $3.53\times$ on \textit{gimple-match.c} and
\textit{insn-emit.c} by using 64 jobs. This is close to the
maximum theoretical speedup of $4\times$ computed by
\cite{bernardino2020improving} when parallelizing the
Intraprocedural Optimizations.

We will now discuss how these changes impacts the overall compilation
time of some projects. For this, we run experiments compiling
the Linux Kernel 5.19.6, Git 2.30.0, the GCC version mentioned in
Section \ref{sec:methods} with and without bootstrap enabled, and JSON C++, with
commit hash \texttt{01f6b2e7418537}. We have also compiled GCC and
Git with the jobserver integration enabled, and the reason because
we did not enabled it in other projects is because it is necessary
to modify a absolutely large number of Makefiles (for instance, Linux
has 2597 Makefiles). 

\begin{figure}
\centering
	 \includegraphics[scale=0.65]{figuras/times-insns-crop.pdf}
	  \caption{Compilation of each file with 1, 2, 4, and 8 threads on
	  Core-i7}
	  \label{fig:gcc_all_files}
\end{figure}

In Fig. \ref{fig:gcc_projects} we show our results. We can observe
a near $35\%$ improvement when compiling GCC with bootstrap disabled,
a $25\%$ when bootstrap is enabled, and $15\%$
improvement when compiling Git with respect to
\texttt{make -j64} alone. Our jobserver implementation also
squeezed a small improvement in GCC compilation, but yielded a massive
slowdown in Git. This is because Jobserver integration comes with
a cost of IPC with Make, which is a problem if the size of the partitions
are small.  These tests were executed with 64 Makefile
jobs and 8 threads inside the compiler. Other than this, we seen
no significant speedup or slowdown in these other projects.

\begin{figure}
\centering
	 \includegraphics[scale=0.8]{figuras/experiment_projects_new-crop.pdf}
	  \caption{Compilation of some projects with 64 Makefile jobs and 8 threads in compiler}
	  \label{fig:gcc_projects}
\end{figure}

\section{Conclusions and Future Works}\label{sec:future_works}

We have shown a tangible way of compiling files in parallel capable
of being implemented in industrial compilers, which resulted in
speedups when compiling single files in parallel, as well as some
speedup when compiling entire projects in manycore machines. However,
There are several points in which our work can be improved.

First, is by fixing the problems reported in Section \ref{sec:methods}. These bugs
certainly prevents the current branch to be used in industrial environments (which is a
good reason why this was not merged in upstream yet), but they are fine as a
proof of concept to support our claims.

Second is by implementing a better partitioner to the project. One main issue
with our partitioner is that we kept its load balancing algorithm minimal to
ensure that it works. Using the LTO default partitioner as a base is a good start.

Third, by modifying the driver to also support external compiler through GCC
SPEC language. Current implementation only checks if launching program
is a known compier/assembler/linker, and will get confused in languages that
needs additional steps (such as CUDA).

And forth, try to develop a predictive model to decide if the input file is
a good candidate for parallel compilation. Fig. \ref{fig:gcc_all_files} shows
a clear linear correlation between the expected number of instructions and time
(and maybe it is the best parameter), but it may be possible to (statically)
collect more information about the file for a better decision.

We also would like to draw attention to LTO's WPA step, which still runs
sequentially. Parallelizing this step, which includes all interprocedural
optimization passes would improve parallel compilation of projects across the
board in both LTO mode and in our work. Profiling shows us that $11\%$ of the
compilation time is spent in this mode, while our project parallelized $75\%$
of the compiler.

%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
%\begin{thebibliography}{8}
%\bibitem{ref_article1}
%Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)
%
%\bibitem{ref_lncs1}
%Author, F., Author, S.: Title of a proceedings paper. In: Editor,
%F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
%Springer, Heidelberg (2016). \doi{10.10007/1234567890}
%
%\bibitem{ref_book1}
%Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
%Location (1999)
%
%\bibitem{ref_proc1}
%Author, A.-B.: Contribution title. In: 9th International Proceedings
%on Proceedings, pp. 1--2. Publisher, Location (2010)
%
%\bibitem{ref_url1}
%LNCS Homepage, \url{http://www.springer.com/lncs}. Last accessed 4
%Oct 2017
%\end{thebibliography}

\bibliographystyle{splncs04}
\bibliography{bibliography}

\end{document}
